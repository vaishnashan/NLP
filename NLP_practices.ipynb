{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNsDBkwhSBL65GNUsV/lzCk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaishnashan/NLP/blob/main/NLP_practices.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"wordnet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTyoRvO_uNsL",
        "outputId": "b4e5f4ad-1183-4b86-e835-61eec8d8c1c0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import string\n",
        "import re"
      ],
      "metadata": {
        "id": "OHGhwLwNt9io"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "josTtta9tijP",
        "outputId": "0004badb-9e0e-44db-e8a7-3251949b1f8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Running', 'great', 'enjoy', 'running', 'park']\n"
          ]
        }
      ],
      "source": [
        "# Example of text preprocessing using these libraries\n",
        "text = \"Running is great! I enjoy running in the park.\"\n",
        "\n",
        "# Remove punctuation\n",
        "text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "# Remove stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "words = text.split()\n",
        "filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "\n",
        "# Lemmatization\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
        "\n",
        "print(lemmatized_words)  # Output: ['running', 'great', 'enjoy', 'running', 'park']\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "text = \"The year 2024 is the present year, and 2025 is upcoming.\"\n",
        "text = re.sub(r'\\d+', '', text)\n",
        "print(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNy5FROWuOuU",
        "outputId": "29dbf085-f31a-4f6f-e4d9-0f33a8768792"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The year  is the present year, and  is upcoming.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "text = \"Hello, world! This is a test.\"\n",
        "text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "print(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8m9YYU_vvqM",
        "outputId": "8975eede-cddb-4219-ad97-356a704f1797"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello world This is a test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download the stopwords list\n",
        "nltk.download('stopwords')\n",
        "\n",
        "text = \"This is a simple example of text processing.\"\n",
        "text = text.lower()  # Convert text to lowercase\n",
        "text = ' '.join([word for word in text.split() if word not in stopwords.words('english')])  # Remove stopwords\n",
        "print(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeJaqqsQwOqq",
        "outputId": "4de4f4b4-5e35-4e50-e3b1-17979a5f754d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "simple example text processing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Download WordNet data\n",
        "nltk.download('wordnet')\n",
        "\n",
        "text = \"The cats are running faster than the dogs.\"\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Lemmatization\n",
        "text = ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n",
        "print(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHDmu78Fyh0Q",
        "outputId": "0509f4e3-1325-4c6b-b691-add801b0e9d5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The cat are running faster than the dogs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Sample preprocessed reviews\n",
        "preprocessed_reviews = [\n",
        "    \"The movie was amazing\",\n",
        "    \"I loved the movie, it was fantastic\",\n",
        "    \"The film was terrible, I didn't enjoy it\"\n",
        "]\n",
        "\n",
        "# Initialize TF-IDF vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit-transform the reviews\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(preprocessed_reviews)\n",
        "\n",
        "# Convert the TF-IDF matrix to DataFrame for better visualization\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AWQ7PtO8yiMK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the resulting DataFrame\n",
        "print(tfidf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AI5x2ufG07dt",
        "outputId": "6ea6f50c-c9dc-4579-e9a7-382b0758a8f2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 9)\t0.39148397136265967\n",
            "  (0, 7)\t0.5041068915759233\n",
            "  (0, 10)\t0.39148397136265967\n",
            "  (0, 0)\t0.6628399823470976\n",
            "  (1, 9)\t0.30083189009819455\n",
            "  (1, 7)\t0.3873758317012295\n",
            "  (1, 10)\t0.30083189009819455\n",
            "  (1, 6)\t0.5093526665422775\n",
            "  (1, 5)\t0.3873758317012295\n",
            "  (1, 3)\t0.5093526665422775\n",
            "  (2, 9)\t0.25712876433201076\n",
            "  (2, 10)\t0.25712876433201076\n",
            "  (2, 5)\t0.33110010014200913\n",
            "  (2, 4)\t0.43535684236960664\n",
            "  (2, 8)\t0.43535684236960664\n",
            "  (2, 1)\t0.43535684236960664\n",
            "  (2, 2)\t0.43535684236960664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the resulting DataFrame\n",
        "print(tfidf_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQKCoacv098s",
        "outputId": "ded872dd-2853-4d39-c28c-f09c2b6b2634"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   amazing      didn     enjoy  fantastic      film        it     loved  \\\n",
            "0  0.66284  0.000000  0.000000   0.000000  0.000000  0.000000  0.000000   \n",
            "1  0.00000  0.000000  0.000000   0.509353  0.000000  0.387376  0.509353   \n",
            "2  0.00000  0.435357  0.435357   0.000000  0.435357  0.331100  0.000000   \n",
            "\n",
            "      movie  terrible       the       was  \n",
            "0  0.504107  0.000000  0.391484  0.391484  \n",
            "1  0.387376  0.000000  0.300832  0.300832  \n",
            "2  0.000000  0.435357  0.257129  0.257129  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oxgMd91z1A2v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}